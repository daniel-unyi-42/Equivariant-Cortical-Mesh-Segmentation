{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f32ea91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "seed = 123\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "np.random.seed(seed)\n",
    "\n",
    "n_folds = 10 # n-fold cross-validation\n",
    "batch_size = 10 # number of meshes in a minibatch\n",
    "breakpoint = 100 # if validation loss does not decrease after this number of epochs, we break the training loop\n",
    "post_train = True # post train with SGD + momentum (lr=0.001, momentum=0.9)\n",
    "\n",
    "misalign = False # whether to misalign the meshes (i.e. apply random isometric transformations to them)\n",
    "realign = False # whether to realign the meshes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea60cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import HCPDataset\n",
    "from data_utils import align_meshes, connect_nodes, RandomIsoTransform\n",
    "from torch_geometric.transforms import Compose\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "from torch_geometric.transforms import NormalizeScale\n",
    "\n",
    "data_path = 'data'\n",
    "!rm -r data/processed\n",
    "\n",
    "pre_transform = Compose(\n",
    "    (\n",
    "        connect_nodes,\n",
    "        NormalizeFeatures(),\n",
    "        NormalizeScale(),\n",
    "        RandomIsoTransform(global_=not misalign),\n",
    "    )\n",
    ")\n",
    "\n",
    "dataset = HCPDataset(data_path, pre_transform=pre_transform)\n",
    "\n",
    "if realign:\n",
    "    dataset = align_meshes(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc84859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import models\n",
    "from mlp import MLP\n",
    "from gnn import GNN\n",
    "from egnn import EGNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3a59b7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "from data_utils import split_fold\n",
    "from train_test import train_model, test_model\n",
    "from metrics import plot_learning_curve\n",
    "\n",
    "test_losses = []\n",
    "test_IoUs = []\n",
    "for fold in range(n_folds):\n",
    "    train_subset, val_subset, test_subset = split_fold(dataset, fold, n_folds)\n",
    "    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_subset, batch_size=len(val_subset), shuffle=True)\n",
    "    test_loader = DataLoader(test_subset, batch_size=len(test_subset), shuffle=True)\n",
    "    model = MLP(device, 12, 32, 3)\n",
    "    # model = GNN(device, 12, 32, 3, residual=False)\n",
    "    # model = EGNN(device, 9, 32, 3, residual=False)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    print(model)\n",
    "    print('Number of parameters: ', sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "    val_losses = []\n",
    "    val_IoUs = []\n",
    "    # train with Adam\n",
    "    best_val_index = -1\n",
    "    for epoch in range(200 * breakpoint):\n",
    "        train_loss, train_IoU = train_model(train_loader, model, optimizer)\n",
    "        val_loss, val_IoU = test_model(val_loader, model)\n",
    "        val_loss = val_loss.cpu().detach().numpy()\n",
    "        new_min = \" \"\n",
    "        if epoch > 0:\n",
    "            if val_losses[best_val_index] > val_loss:\n",
    "                new_min = \"*\"\n",
    "                best_val_index = epoch\n",
    "                torch.save(model, \"models/best_model_%d.pkl\" % fold)\n",
    "            if epoch - best_val_index > breakpoint:\n",
    "                break\n",
    "        val_losses.append(val_loss)\n",
    "        val_IoUs.append(val_IoU)\n",
    "        print(new_min,\n",
    "              \"Epoch: %d, train loss: %1.3f, train IoU/class: %1.3f %1.3f %1.3f, val loss: %1.3f, val IoU/class: %1.3f %1.3f %1.3f\" \\\n",
    "              % (epoch, train_loss, train_IoU[0], train_IoU[1], train_IoU[2], val_loss, val_IoU[0], val_IoU[1], val_IoU[2]))\n",
    "    model = torch.load(\"models/best_model_%d.pkl\" % fold)\n",
    "    if post_train:\n",
    "        model.optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "        best_val_index = -1\n",
    "        for epoch in range(200):\n",
    "            train_loss, train_IoU = train_model(train_loader, model, optimizer)\n",
    "            val_loss, val_IoU = test_model(val_loader, model)\n",
    "            val_loss = val_loss.cpu().detach().numpy()\n",
    "            new_min = \" \"\n",
    "            if epoch > 0:\n",
    "                if val_losses[best_val_index] > val_loss:\n",
    "                    new_min = \"*\"\n",
    "                    best_val_index = epoch\n",
    "                    torch.save(model, \"models/best_model_%d.pkl\" % fold)\n",
    "            val_losses.append(val_loss)\n",
    "            val_IoUs.append(val_IoU)\n",
    "            print(new_min,\n",
    "                  \"Epoch: %d, train loss: %1.3f, train IoU/class: %1.3f %1.3f %1.3f, val loss: %1.3f, val IoU/class: %1.3f %1.3f %1.3f\" \\\n",
    "                  % (epoch, train_loss, train_IoU[0], train_IoU[1], train_IoU[2], val_loss, val_IoU[0], val_IoU[1], val_IoU[2]))\n",
    "        model = torch.load(\"models/best_model_%d.pkl\" % fold)\n",
    "    # test model\n",
    "    test_loss, test_IoU = test_model(test_loader, model)\n",
    "    test_loss = test_loss.cpu().detach().numpy()\n",
    "    test_losses.append(test_loss)\n",
    "    test_IoUs.append(test_IoU)\n",
    "    print(\"Fold: %d, test loss: %1.3f, test IoU/class: %1.3f %1.3f %1.3f\" % (fold, test_loss, test_IoU[0], test_IoU[1], test_IoU[2]))\n",
    "    plot_learning_curve(val_losses, val_IoUs)\n",
    "\n",
    "print(sum(test_losses) / len(test_losses))\n",
    "print(sum(test_IoUs) / len(test_IoUs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983fc384",
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_IoU in test_IoUs:\n",
    "    print(test_IoU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0b2073",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
